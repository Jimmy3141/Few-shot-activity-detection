{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "from utility import load_categories\n",
    "\n",
    "from utility import cp_to_date,load_appliance_time, time_lst_to_dic, merge_overlapping_intervals, plot_activity, load_daily_activity_dic,load_activity_dic\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def merge_overlapping_intervals(appliance_time, tolerance):\n",
    "    # 将时间对转换为pandas的Timestamp对象并按开始时间排序\n",
    "    appliance_time = sorted([(pd.Timestamp(start), pd.Timestamp(end)) for start, end in appliance_time], key=lambda x: x[0])\n",
    "\n",
    "    # 合并重叠的时间段\n",
    "    merged_intervals = []\n",
    "    for start, end in appliance_time:\n",
    "        # 如果列表为空或当前时间段的开始时间大于合并列表中最后一个时间段的结束时间/两事件发生间隔小于大于5分钟，则添加新的时间段\n",
    "        if merged_intervals==[]:\n",
    "            merged_intervals.append([start, end])\n",
    "        elif start-merged_intervals[-1][1]>timedelta(minutes=tolerance):\n",
    "            merged_intervals.append([start, end])\n",
    "        else:\n",
    "            # 否则，更新合并列表中最后一个时间段的结束时间为当前时间段的结束时间\n",
    "            merged_intervals[-1][1] = max(merged_intervals[-1][1], end)\n",
    "\n",
    "    # 将合并后的时间段转换为元组并返回\n",
    "    return [(start, end) for start, end in merged_intervals]\n",
    "\n",
    "def appiance_activity_association(cp_path, appliance_path, appliance_lst, tolerance):\n",
    "    # load changepoints\n",
    "    with open(cp_path,'rb') as f:\n",
    "        all_cp = pickle.load(f)\n",
    "    cp_time = cp_to_date(all_cp,\"2013-05-01 00:00:00\",365)\n",
    "    cp_time = [(cp_time[i], cp_time[i+1]) for i in range(len(cp_time)-1)]\n",
    "\n",
    "    # process appliance\n",
    "    appliance_time = load_appliance_time(appliance_path,appliance_lst)\n",
    "    temporary_lst = [] # buffer\n",
    "    for _, item in appliance_time.items():\n",
    "        temporary_lst += item\n",
    "    appliance_time = temporary_lst\n",
    "    appliance_time = sorted(appliance_time, key=lambda x: x[0])\n",
    "    appliance_time = merge_overlapping_intervals(appliance_time,tolerance)\n",
    "    activity = find_activities(appliance_time, cp_time)\n",
    "    return activity\n",
    "\n",
    "def find_activities(cooking_time, meter_changes):\n",
    "    activity = []\n",
    "    # 遍历每一个变点监测时间段\n",
    "    for start_meter, end_meter in meter_changes:\n",
    "        min_start = None\n",
    "        max_end = None\n",
    "\n",
    "        # 检查cooking_time中是否有时间段与当前变点监测时间段重叠\n",
    "        for start_cook, end_cook in cooking_time:\n",
    "            if start_meter< start_cook < end_meter:\n",
    "                # 找到重叠时间段中的最早开始时间和最晚结束时间\n",
    "                if min_start is None or start_cook < min_start:\n",
    "                    min_start = start_cook\n",
    "                if max_end is None or end_cook > max_end:\n",
    "                    max_end = end_cook\n",
    "                cooking_time.remove((start_cook,end_cook))\n",
    "\n",
    "        # 如果存在重叠时间段，则将其添加到activity列表中\n",
    "        if min_start is not None and max_end is not None:\n",
    "            activity.append((min_start, max_end))\n",
    "\n",
    "    return activity\n",
    "acitivity_path = r'C:\\Users\\ASUS\\Desktop\\Few-shot NILM (2)\\activity_annotation\\time_data\\cleaning'\n",
    "cp_path = r\"change_points_30s_120.pkl\"\n",
    "entertainment = appiance_activity_association(cp_path, acitivity_path, ['washing_machine','dishwasher',\n",
    "                                                    'hair_dryer','straighteners',\"iron\",'vacuum'],30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path=r'C:\\annoticity-master (2)\\anno\\datasets\\UK_DALE\\ukdale.h5'\n",
    "# cleaning_df = load_categories(file_path, [22], [\"hoover\"], 'active')\n",
    "kitchen_df = load_categories(file_path, [10,11,13,16,42], [\"kettle\", \"toaster\",'microwave',\"breadmaker\",\"gas oven\"], 'active')\n",
    "entertainment_df = load_categories(file_path, [7,9,17,28],[\"tv\", \"htpc\",\"amp_livingroom\",' subwoofer_livingroom'],'active')\n",
    "cleaning_df = load_categories(file_path, [5,6,39,40,41,22],['washing machine','dishwasher',\n",
    "                                                    'hair dryer','straighteners',\"iron\",'vacuum'],'active')\n",
    "aggregate_df = load_categories(file_path, [1],[\"aggregated\"], 'apparent')\n",
    "office_df = load_categories(file_path, [4,51,53],['laptop','office_pc','printer'],'active')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "activity_path = r'C:\\Users\\ASUS\\Desktop\\Few-shot NILM (2)\\activity_annotation\\activity_120'\n",
    "activity =load_daily_activity_dic(activity_path, ['cooking','cleaning','entertainment',\"working\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(r'C:\\Users\\ASUS\\Desktop\\Few-shot NILM (2)\\activity_annotation\\activity_120\\cleaning.pkl', 'wb') as f:\n",
    "#     pickle.dump(entertainment, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"change_points_30s_120.pkl\",'rb') as f:\n",
    "    cp = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = pd.to_datetime(\"2013-10-24 00:00:00\")\n",
    "end = pd.to_datetime(\"2013-10-25 00:00:00\")\n",
    "time_difference = start - pd.to_datetime(\"2013-05-01 00:00:00\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_difference.days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aggregate_df.index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(aggregate_df[start:end], label=\"aggregate\")\n",
    "for i in np.array(cp[176])-10:\n",
    "    plt.axvline(aggregate_df[start:end].index[i].tz_convert('Europe/London'), color=\"red\")\n",
    "plt.savefig('cp_detection.jpg')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = pd.to_datetime(\"2013-10-26 00:00:00\")\n",
    "end = pd.to_datetime(\"2013-10-27 00:00:00\")\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.plot(aggregate_df[start:end], label=\"aggregate\")\n",
    "for i in np.array(cp[176])-10:\n",
    "    plt.axvline(aggregate_df[start:end].index[i].tz_convert('Europe/London'), color=\"red\")\n",
    "####################\n",
    "plt.subplot(5, 1, 2)\n",
    "for i in kitchen_df.columns:\n",
    "    plt.plot(kitchen_df[i][start:end].index, kitchen_df[i][start:end].values, label=i)\n",
    "for start_time, end_time in activity['cooking'][start.date()]:\n",
    "    plt.axvline(pd.to_datetime(start_time).tz_localize('Europe/London'), color=\"red\")\n",
    "    plt.axvline(pd.to_datetime(end_time).tz_localize('Europe/London'), color=\"red\")\n",
    "plt.legend()\n",
    "\n",
    "#####################\n",
    "plt.subplot(5, 1, 3)\n",
    "for i in cleaning_df.columns:\n",
    "    plt.plot(cleaning_df[i][start:end].index, cleaning_df[i][start:end].values, label=i)\n",
    "for start_time, end_time in activity['cleaning'][start.date()]:\n",
    "    plt.axvline(pd.to_datetime(start_time).tz_localize('Europe/London'), color=\"red\")\n",
    "    plt.axvline(pd.to_datetime(end_time).tz_localize('Europe/London'), color=\"red\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "############\n",
    "plt.subplot(5, 1, 4)\n",
    "for i in entertainment_df.columns:\n",
    "    plt.plot(entertainment_df[i][start:end].index, entertainment_df[i][start:end].values, label=i)\n",
    "for start_time, end_time in activity['entertainment'][start.date()]:\n",
    "    plt.axvline(pd.to_datetime(start_time).tz_localize('Europe/London'), color=\"red\")\n",
    "    plt.axvline(pd.to_datetime(end_time).tz_localize('Europe/London'), color=\"red\")\n",
    "    plt.grid(\"--\")\n",
    "plt.legend()\n",
    "\n",
    "##########\n",
    "plt.subplot(5, 1, 5)\n",
    "for i in office_df.columns:\n",
    "    plt.plot(office_df[i][start:end].index, office_df[i][start:end].values, label=i)\n",
    "\n",
    "for start_time, end_time in activity['working'][start.date()]:\n",
    "    plt.axvline(pd.to_datetime(start_time).tz_localize('Europe/London'), color=\"red\")\n",
    "    plt.axvline(pd.to_datetime(end_time).tz_localize('Europe/London'), color=\"red\")\n",
    "\n",
    "# for i in kitchen_df.columns:\n",
    "#     plt.plot(kitchen_df[i][start:end].index, kitchen_df[i][start:end].values, label=i)\n",
    "# for start_time, end_time in cooking[start.date()]:\n",
    "#     plt.axvline(pd.to_datetime(start_time).tz_localize('Europe/London'), color=\"red\")\n",
    "#     plt.axvline(pd.to_datetime(end_time).tz_localize('Europe/London'), color=\"red\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('activity.png')\n",
    "plt.savefig('activity.pdf')\n",
    "\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "office_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_path = r'C:\\Users\\ASUS\\Desktop\\Few-shot NILM (2)\\activity_annotation\\activity_120'\n",
    "\n",
    "activity_dic = load_activity_dic(activity_path,[\"cooking\",'cleaning',\"entertainment\",'working'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_dic[\"cooking\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start = [start.time() for start, _ in activity if start<pd.Timestamp('2013-08-01T00:00:00')]\n",
    "# end = [end.time() for _, end in activity if end<pd.Timestamp('2013-08-01T00:00:00')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plot activity duration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "statistic_cp = {\n",
    "    \"cooking\": [600,1200,1320,1680,1920,2400],\n",
    "    'cleaning':[820,1500,2100,2520],\n",
    "    'entertainment':[500,1000,2100],\n",
    "    'working':[820,1600,1900,2200]\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.rcParams.update({\"font.size\":12})\n",
    "# from utility import plot_activity\n",
    "activity_num = len(activity_dic.keys())\n",
    "help_index = 1\n",
    "for activity_name, time_index in activity_dic.items():\n",
    "    plt.subplot(activity_num,1,help_index)\n",
    "    start = [start.time() for start, _ in time_index if start<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    end = [end.time() for _, end in time_index if end<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    plot_activity(start,end)\n",
    "    help_index+=1\n",
    "    plt.ylabel(activity_name)\n",
    "    activity_cp = statistic_cp[activity_name]\n",
    "    for i in activity_cp:\n",
    "        plt.axvline(i,color=\"red\")\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_probability_activity(start,end):\n",
    "    one_day_index = pd.date_range(\"00:00:00\", \"23:59:59\", freq=\"30s\")\n",
    "    one_day_df = pd.DataFrame(index=pd.to_datetime(one_day_index), data=[0]*len(one_day_index))\n",
    "    for start_time, end_time in zip(start,end):\n",
    "        start_time =  one_day_df.index[0]+timedelta(hours=start_time.hour,minutes=start_time.minute,seconds=start_time.second)\n",
    "        end_time = one_day_df.index[0]+timedelta(hours=end_time.hour,minutes=end_time.minute,seconds=end_time.second)\n",
    "        one_day_df[str(start_time):str(end_time)]+=1\n",
    "    return one_day_df.values\n",
    "one_day_statistic = {}\n",
    "for activity_name, time_index in activity_dic.items():\n",
    "    start = [start.time() for start, _ in time_index if start<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    end = [end.time() for _, end in time_index if end<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    one_day_statistic[activity_name] = get_probability_activity(start,end)\n",
    "    print(activity_name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_dic.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_day_statistic.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(one_day_statistic[\"cooking\"])\n",
    "plt.axvline([600])\n",
    "plt.axvline([1200])\n",
    "plt.axvline([1320])\n",
    "plt.axvline([1680])\n",
    "plt.axvline([2550])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plot start,end"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "\n",
    "def plot_probability(start, end, freq=\"10min\"):\n",
    "    start_df = _retrieve_prob_df(start)\n",
    "    end_df = _retrieve_prob_df(end)\n",
    "\n",
    "    # 重采样并归一化\n",
    "    start = start_df.resample(freq).mean()\n",
    "    end = end_df.resample(freq).mean()\n",
    "    start = start / start.sum()\n",
    "    end = end / end.sum()\n",
    "\n",
    "    # 找到时间索引的交集\n",
    "    common_index = start.index.intersection(end.index)\n",
    "    start_common = start.reindex(common_index, method='ffill').fillna(0)\n",
    "    end_common = end.reindex(common_index, method='ffill').fillna(0)\n",
    "\n",
    "    # 计算相交区域\n",
    "    min_values = np.minimum(start_common.values, end_common.values)\n",
    "    max_values = np.maximum(start_common.values, end_common.values)\n",
    "\n",
    "    # 绘制底层区域（先绘制重叠区域下面的区域）\n",
    "    plt.fill_between(start.index, start.values.reshape(-1), color='blue', alpha=0.5)\n",
    "    plt.fill_between(end.index, end.values.reshape(-1), color='red', alpha=0.5)\n",
    "\n",
    "    # 绘制相交区域\n",
    "    plt.fill_between(common_index, min_values.reshape(-1), max_values.reshape(-1), color='purple', alpha=0.7)\n",
    "\n",
    "    # 绘制时间序列\n",
    "    plt.plot(start.index, start.values, color='blue')\n",
    "    plt.plot(end.index, end.values, color='red')\n",
    "\n",
    "    # 标签和网格\n",
    "    plt.yticks([])\n",
    "    plt.grid('--')\n",
    "    plt.legend()\n",
    "\n",
    "    point_index = [start.index[i] for i in range(0,len(start.index),len(start.index)//12)]+[start.index[-1]]\n",
    "    time_index = [str(i) for i in range(0,24,2)]+[24]\n",
    "\n",
    "    plt.xticks(point_index,time_index)\n",
    "\n",
    "\n",
    "def _retrieve_prob_df(time):\n",
    "    one_day_index = pd.date_range(\"00:00:00\", \"23:59:59\", freq=\"30s\")\n",
    "    one_day_df = pd.DataFrame(index=pd.to_datetime(one_day_index), data=[0]*len(one_day_index))\n",
    "    for i in time:\n",
    "        date = datetime.combine(one_day_index[0], i)\n",
    "        one_day_df.loc[str(date)] += 1\n",
    "    return one_day_df\n",
    "plot_probability(start,end)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.rcParams.update({\"font.size\":12})\n",
    "# from utility import plot_activity\n",
    "activity_num = len(activity_dic.keys())\n",
    "help_index = 1\n",
    "for activity_name, time_index in activity_dic.items():\n",
    "    plt.subplot(activity_num,1,help_index)\n",
    "    start = [start.time() for start, _ in time_index if start<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    end = [end.time() for _, end in time_index if end<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "    plot_probability(start,end)\n",
    "    help_index+=1\n",
    "    plt.ylabel(activity_name)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot single activity start end"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity = activity_dic[\"working\"]\n",
    "start = [start.time() for start, _ in activity if start<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "end = [end.time() for _, end in activity if end<pd.Timestamp('2014-05-01T00:00:00')]\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "plt.figure(figsize=(10,5))\n",
    "def plot_probability(start, end, freq=\"10min\"):\n",
    "    start_df = _retrieve_prob_df(start)\n",
    "    end_df = _retrieve_prob_df(end)\n",
    "\n",
    "    # 重采样并归一化\n",
    "    start = start_df.resample(freq).mean()\n",
    "    end = end_df.resample(freq).mean()\n",
    "    start = start / start.sum()\n",
    "    end = end / end.sum()\n",
    "\n",
    "    # 找到时间索引的交集\n",
    "    common_index = start.index.intersection(end.index)\n",
    "    start_common = start.reindex(common_index, method='ffill').fillna(0)\n",
    "    end_common = end.reindex(common_index, method='ffill').fillna(0)\n",
    "\n",
    "    # 计算相交区域的上下界\n",
    "    min_values = np.minimum(start_common.values, end_common.values)\n",
    "    max_values = np.maximum(start_common.values, end_common.values)\n",
    "\n",
    "    # 找到相交区域的颜色\n",
    "    color_intersection = np.where(start_common.values < end_common.values, 'blue', 'red')\n",
    "\n",
    "    # 绘制相交区域\n",
    "    for i in range(len(common_index)-1):\n",
    "        plt.fill_between([common_index[i], common_index[i+1]],\n",
    "                         min_values[i], max_values[i],\n",
    "                         color=color_intersection[i], alpha=0.7)\n",
    "\n",
    "    # 绘制底层区域\n",
    "    plt.fill_between(start.index, start.values.reshape(-1), color='blue', alpha=0.5, label='Start')\n",
    "    plt.fill_between(end.index, end.values.reshape(-1), color='red', alpha=0.5, label='End')\n",
    "\n",
    "    # 绘制时间序列\n",
    "    plt.plot(start.index, start.values.reshape(-1), color='blue')\n",
    "    plt.plot(end.index, end.values.reshape(-1), color='red')\n",
    "\n",
    "    # 标签和网格\n",
    "    plt.yticks([])\n",
    "    plt.grid('--')\n",
    "    plt.legend()\n",
    "\n",
    "    point_index = [start.index[i] for i in range(0,len(start.index),len(start.index)//12)]+[start.index[-1]]\n",
    "    time_index = [str(i) for i in range(0,24,2)]+[24]\n",
    "\n",
    "    plt.xticks(point_index,time_index)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def _retrieve_prob_df(time):\n",
    "    one_day_index = pd.date_range(\"00:00:00\", \"23:59:59\", freq=\"30s\")\n",
    "    one_day_df = pd.DataFrame(index=pd.to_datetime(one_day_index), data=[0]*len(one_day_index))\n",
    "    for i in time:\n",
    "        date = datetime.combine(one_day_index[0], i)\n",
    "        one_day_df.loc[str(date)] += 1\n",
    "    return one_day_df\n",
    "plot_probability(start,end)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
